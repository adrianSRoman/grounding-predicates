{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gridworld\n",
    "\n",
    "Script for generating a dataset of pre/post images of actions performed on random gridworld states."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Configure environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"SDL_VIDEODRIVER\"] = \"dummy\"\n",
    "os.environ[\"PYGAME_HIDE_SUPPORT_PROMPT\"] = \"1\"\n",
    "import yaml\n",
    "\n",
    "import pygame\n",
    "pygame.init()\n",
    "\n",
    "import symbolic\n",
    "from config import EnvironmentPaths\n",
    "\n",
    "paths = EnvironmentPaths(environment=\"gridworld\")\n",
    "pddl = symbolic.Pddl(str(paths.domain_pddl), str(paths.problem_pddl))\n",
    "\n",
    "with open(paths.env / \"config.yaml\") as f:\n",
    "    config = yaml.full_load(f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define state generation functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import typing\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from env.gridworld import propositions\n",
    "from env.gridworld.dataset import LogDatabase\n",
    "from env.gridworld.propositions import ArgumentTypeError, PropositionValueError\n",
    "from env.gridworld.world import World\n",
    "\n",
    "def random_state(pddl, config, state=set(), prob_proposition_on=0.05, log=None):\n",
    "    \"\"\"Generate random world state.\n",
    "    \n",
    "    Args:\n",
    "        pddl (symbolic.Pddl): Pddl instance.\n",
    "        config (dict): World config.\n",
    "        state (set(str), optional): Initial state (default empty).\n",
    "        prob_proposition_on (double, optional): Probability of turning a proposition on (default 0.05).\n",
    "        log (text file, optional): Print debug statements to this file (default None).\n",
    "    Returns:\n",
    "        (set(str)): Random symbolic state as a set of propositions.\n",
    "    \"\"\"\n",
    "    # Empty world for prop testing\n",
    "    world_test = World(pddl, config, state, log=log)\n",
    "    \n",
    "    # Iterate over all propositions\n",
    "    state_index = pddl.state_index\n",
    "    for i in range(len(state_index)):\n",
    "        # Select prob_pred_on predicates\n",
    "        if random.random() > prob_proposition_on:\n",
    "            continue\n",
    "\n",
    "        prop = state_index.get_proposition(i)\n",
    "\n",
    "        # Check prop for consistency\n",
    "        try:\n",
    "            world_test.state.add(prop, validate=True)\n",
    "        except (ArgumentTypeError, PropositionValueError) as e:\n",
    "            if log is not None:\n",
    "                log.write(f\"! {e}\")\n",
    "                # Try to remove prop if added in the state.\n",
    "                # Need to check existence before removing because\n",
    "                # prop may not be constructable with invalid args.\n",
    "                if prop in world_test.state.stringify():\n",
    "                    try:\n",
    "                        world_test.state.remove(prop)\n",
    "                    except (KeyError, ValueError) as e:\n",
    "                        log.write(f\"! {e}\")\n",
    "            continue\n",
    "\n",
    "    world_test.place_objects()\n",
    "    return pddl.derived_state(world_test.state.stringify())\n",
    "\n",
    "def generate_pre_post(\n",
    "    pddl: symbolic.Pddl,\n",
    "    config: typing.Dict,\n",
    "    action_call: str,\n",
    "    conj: symbolic.PartialState,\n",
    "    log: typing.Optional[LogDatabase] = None\n",
    ") -> [typing.Tuple[typing.Tuple[np.ndarray, np.ndarray, np.ndarray], typing.Tuple[np.ndarray, np.ndarray, np.ndarray]]]:\n",
    "    \"\"\"Generate pre/post images of given action performed on a random state.\n",
    "    \n",
    "    Args:\n",
    "        pddl: Pddl instance.\n",
    "        config: World config.\n",
    "        action_call: Action call.\n",
    "        conj: Precondition dnf conjunction.\n",
    "        log: Print debug statements to this file (default None).\n",
    "    Returns:\n",
    "        (image [220, 220, 3], state [N], boxes [O, 4]) ftuple for pre- and post-conditions each.\n",
    "    \"\"\"\n",
    "    # Generate random state\n",
    "    s_random = random_state(pddl, config, conj.pos, log=log) - conj.neg\n",
    "    s = conj.pos | s_random\n",
    "    if log is not None:\n",
    "        log.write(f\"s_random: {s_random}\")\n",
    "        log.write(f\"s_combined: {s}\")\n",
    "\n",
    "    # Initialize world\n",
    "    world = World(pddl, config, s, log=log, validate=True)\n",
    "    world.place_objects()\n",
    "    \n",
    "    # Check that world did not reintroduce negative propositions\n",
    "    s_neg = set(propositions.alias(prop) for prop in conj.neg)\n",
    "    s = world.state.stringify()\n",
    "    if s & s_neg:\n",
    "        raise PropositionValueError(f\"Conflicting propositions:\\ns:{s}\\ns_neg:{s_neg}\")\n",
    "\n",
    "    # Render pre and post images\n",
    "    img_pre = world.render()\n",
    "    s_pre = pddl.state_index.get_indexed_state(world.state.stringify())\n",
    "    boxes_pre = world.get_bounding_boxes()\n",
    "    \n",
    "    world.execute(action_call)\n",
    "    img_post = world.render()\n",
    "    s_post = pddl.state_index.get_indexed_state(world.state.stringify())\n",
    "    boxes_post = world.get_bounding_boxes()\n",
    "    \n",
    "    return (img_pre, s_pre, boxes_pre), (img_post, s_post, boxes_post)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define IO functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "class Stdout:\n",
    "    \"\"\"Dummy class for logging to stdout.\"\"\"\n",
    "    def write(self, message):\n",
    "        print(message)\n",
    "\n",
    "def save_images(log, img_pre, img_post):\n",
    "    \"\"\"Save pre and post images with the current log key.\n",
    "    \n",
    "    Args:\n",
    "        log (env.gridworld.dataset.LogDatabase): Log database.\n",
    "        img_pre (np.ndarray): Pre image.\n",
    "        img_post (np.ndarray): Post image.\n",
    "    \"\"\"\n",
    "    plt.imsave(log.path_images / f\"{log.key}_pre.png\", img_pre)\n",
    "    plt.imsave(log.path_images / f\"{log.key}_post.png\", img_post)\n",
    "    \n",
    "def load_images(log, key):\n",
    "    \"\"\"Load pre and post images from the given log key.\n",
    "    \n",
    "    Args:\n",
    "        log (env.gridworld.dataset.LogDatabase): Log database.\n",
    "        key (int): Log to load.\n",
    "    Returns:\n",
    "        (np.ndarray, np.ndarray): Pair of pre, post images\n",
    "    \"\"\"\n",
    "    img_pre = plt.imread(log.path_images / f\"{key}_pre.png\")\n",
    "    img_post = plt.imread(log.path_images / f\"{key}_post.png\")\n",
    "    return (img_pre, img_post)\n",
    "\n",
    "def render_images(img_pre, img_post):\n",
    "    \"\"\"Render pre and post images side-by-side.\n",
    "    \n",
    "    Args:\n",
    "        img_pre (np.ndarray): Pre image.\n",
    "        img_post (np.ndarray): Post image.\n",
    "    \"\"\"\n",
    "    fig = plt.figure(figsize=(14, 7))\n",
    "    ax1 = plt.subplot(121)\n",
    "    ax1.imshow(img_pre, interpolation='none')\n",
    "    ax2 = plt.subplot(122)\n",
    "    ax2.imshow(img_post, interpolation='none')\n",
    "    plt.show()\n",
    "\n",
    "def save_variables(log, pddl, config, action_call, conj, debug: bool = True):\n",
    "    \"\"\"Save the given variables, along with the current random seed, at the current log key.\n",
    "    \n",
    "    Args:\n",
    "        log (env.gridworld.dataset.LogDatabase): Log database.\n",
    "        pddl (symbolic.Pddl): Pddl instance.\n",
    "        config (dict): World config.\n",
    "        action_call (str): Action call.\n",
    "        conj (symbolic.PartialState): Precondition dnf conjunction.\n",
    "        debug: Save all variables if true, otherwise save only necessary variables.\n",
    "    \"\"\"\n",
    "    if debug:\n",
    "        log.save({\n",
    "            \"pddl\": pddl,\n",
    "            \"config\": config,\n",
    "            \"action_call\": action_call,\n",
    "            \"conj\": conj,\n",
    "            \"state_random\": random.getstate(),\n",
    "            \"state_np_random\": np.random.get_state(),\n",
    "        })\n",
    "    else:\n",
    "        log.save({\n",
    "            \"action_call\": action_call,\n",
    "        })\n",
    "\n",
    "def load_variables(log, key, verbose=True):\n",
    "    \"\"\"Load the saved variables, along with the saved random seed, at the given log key.\n",
    "    \n",
    "    Optionally print the saved log.\n",
    "    \n",
    "    Args:\n",
    "        log (env.gridworld.dataset.LogDatabase): Log database.\n",
    "        key (int): Log to load.\n",
    "        verbose (bool, optional): Whether to print the log (default True).\n",
    "    Returns:\n",
    "        (pddl, config, action_call, conj): Tuple of saved variables.\n",
    "    \"\"\"\n",
    "    # Load variables\n",
    "    variables = log.load(key, verbose=verbose)\n",
    "    pddl = variables[\"pddl\"]\n",
    "    config = variables[\"config\"]\n",
    "    action_call = variables[\"action_call\"]\n",
    "    conj = variables[\"conj\"]\n",
    "    \n",
    "    # Set random state\n",
    "    random.setstate(variables[\"state_random\"])\n",
    "    np.random.set_state(variables[\"state_np_random\"])\n",
    "    \n",
    "    return pddl, config, action_call, conj"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate dataset\n",
    "\n",
    "Logs, images, and variables are saved in `data/gridworld`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import traceback\n",
    "\n",
    "import tqdm.notebook\n",
    "\n",
    "from gpred import dnf_utils\n",
    "\n",
    "def generate_dataset(size_dataset: int = 10000, debug: bool = False):\n",
    "    \"\"\"Generates dataset by saving png images and logging variables to disk.\n",
    "    \n",
    "    Args:\n",
    "        size_dataset: Minimum number of entries in dataset.\n",
    "    \"\"\"\n",
    "    # Create log database for saving data\n",
    "    log = LogDatabase(path=paths.data)\n",
    "\n",
    "    # Set random seed\n",
    "    random.seed(0)\n",
    "    np.random.seed(0)\n",
    "\n",
    "    # Iterate over all actions\n",
    "    idx = 0\n",
    "    num_generated = 0\n",
    "    loop = tqdm.notebook.tqdm(total=size_dataset)\n",
    "    while num_generated < size_dataset:\n",
    "        for action in pddl.actions:\n",
    "            # Iterate over all parameter combinations for action\n",
    "            for args in action.parameter_generator:\n",
    "                action_call = action.to_string(args)\n",
    "\n",
    "                # Get pre/post conditions\n",
    "                pre_post = dnf_utils.get_normalized_conditions(pddl, action_call, apply_axioms=True)\n",
    "\n",
    "                if pre_post is None:\n",
    "                    # No valid normalized conditions (violated axioms)\n",
    "                    continue\n",
    "\n",
    "                # Iterate over precondition conjunctions\n",
    "                pre, post = pre_post\n",
    "                for conj in pre.conjunctions:\n",
    "                    # Initialize log\n",
    "                    log.key = idx\n",
    "                    save_variables(log, pddl, config, action_call, conj, debug=debug)\n",
    "                    log.write(f\"{action_call}\")\n",
    "                    log.write(\"=========================\")\n",
    "                    log.write(f\"idx: {idx}\")\n",
    "                    log.write(f\"s: {conj.pos}\")\n",
    "\n",
    "                    try:\n",
    "                        # Generate images\n",
    "                        (img_pre, s_pre, boxes_pre), (img_post, s_post, boxes_post) = generate_pre_post(pddl, config, action_call, conj, log=log)\n",
    "                    except (ArgumentTypeError, PropositionValueError) as e:\n",
    "                        with open(paths.data / \"warnings.log\", \"a+\") as f:\n",
    "                            f.write(f\"{log.key}: {e.__class__.__name__}: {e}\\n\")\n",
    "                            log.write(traceback.format_exc())\n",
    "                    except Exception as e:\n",
    "                        with open(paths.data / \"exceptions.log\", \"a+\") as f:\n",
    "                            tb = traceback.format_exc()\n",
    "                            f.write(f\"{log.key}: {e.__class__.__name__}: {e}\\n{tb}\\n\")\n",
    "                            log.write(tb)\n",
    "                    else:\n",
    "                        # Save images\n",
    "                        save_images(log, img_pre, img_post)\n",
    "\n",
    "                        # Save state\n",
    "                        log.save({\"s_pre\": s_pre, \"s_post\": s_post, \"boxes_pre\": boxes_pre, \"boxes_post\": boxes_post})\n",
    "\n",
    "                        # Increment index\n",
    "                        num_generated += 1\n",
    "                        if idx <= size_dataset:\n",
    "                            loop.update(1)\n",
    "\n",
    "                    # Increment log index\n",
    "                    log.commit()\n",
    "                    idx += 1\n",
    "\n",
    "    # Close loop\n",
    "    print(f\"Generated {num_generated} out of {size_dataset}\")\n",
    "    loop.close()\n",
    "\n",
    "    # Reset log key\n",
    "    log.key = \"stdout\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "generate_dataset(100000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save dataset\n",
    "\n",
    "Take logs, images, and variables from `data/gridworld` and convert them to vector format in `data/gridworld/dataset.h5`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from env.gridworld.dataset import LogDatabase\n",
    "import tqdm.notebook\n",
    "\n",
    "# Create log database in case previous cell was not run\n",
    "log = LogDatabase(path=paths.data)\n",
    "\n",
    "log.publish_dataset(\"dataset.hdf5\", tqdm=tqdm.notebook.tqdm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections\n",
    "\n",
    "import h5py\n",
    "\n",
    "idx_pre_post = collections.defaultdict(lambda: 0)\n",
    "with h5py.File(paths.data / \"dataset.hdf5\", \"r\") as f:\n",
    "    D = len(f[\"actions\"])\n",
    "    with h5py.File(paths.data / \"dataset_half.hdf5\", \"w\") as f_out:\n",
    "        dset = f_out.create_dataset(\"idx_pre_post\", (D,), dtype=int)\n",
    "        for idx_data, action in enumerate(f[\"actions\"]):\n",
    "            dset[idx_data] = idx_pre_post[action]\n",
    "            idx_pre_post[action] = 1 - idx_pre_post[action]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "with h5py.File(paths.data / \"dataset_half.hdf5\", \"r\") as f:\n",
    "    print(np.array(f[\"idx_pre_post\"]).sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Compute image distribution\n",
    "Comment out the image normalization transform inside the Problem class before running this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment = Experiment(device)\n",
    "for path_run in experiment:\n",
    "    problem = experiment.problem\n",
    "    problem.compute_image_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analyze Dataset Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import tqdm\n",
    "\n",
    "from gpred import dnf_utils\n",
    "\n",
    "\n",
    "def plot_predicate_counts(stats: pd.DataFrame):\n",
    "    \"\"\"Plots predicates (x) vs. count (y).\n",
    "    \n",
    "    Args:\n",
    "        stats: Longform dataframe output by `compute_pddl_statistics()`.\n",
    "    \"\"\"\n",
    "    f, ax = plt.subplots(figsize=(20, 10))\n",
    "\n",
    "    sns.set_style(\"whitegrid\")\n",
    "    g = sns.countplot(data=stats.sort_values(\"Predicate\"), x=\"Predicate\", hue=\"Label\")\n",
    "    for item in g.get_xticklabels():\n",
    "        item.set_rotation(90)\n",
    "\n",
    "def plot_dnfs(stats: pd.DataFrame):\n",
    "    \"\"\"Plots a heatmap of actions vs. propositions specified by their DNFs.\n",
    "    \n",
    "    Args:\n",
    "        stats: Longform table output by compute_pddl_statistics().\n",
    "    \"\"\"\n",
    "    SIZE_SECTION = 10\n",
    "    CMAP = sns.diverging_palette(10, 130, n=100)\n",
    "    \n",
    "    df_action_v_prop = stats.astype({\"Label\": float}).pivot(index=[\"Action\", \"Condition\"], columns=\"Proposition\", values=\"Label\")\n",
    "    num_rows = len(df_action_v_prop)\n",
    "    num_sections = math.ceil(num_rows / SIZE_SECTION)\n",
    "\n",
    "    f, axs = plt.subplots(num_sections, 1, figsize=(10, num_sections * 5))\n",
    "\n",
    "    for i in tqdm.notebook.tqdm(range(num_sections)):\n",
    "        plt.subplot(num_sections, 1, i + 1)\n",
    "        g = sns.heatmap(data=df_action_v_prop[i*SIZE_SECTION:min(len(df_action_v_prop), (i+1)*SIZE_SECTION)], square=True, cmap=CMAP, linewidths=0.5, linecolor=\"#eee\", cbar_kws={\"shrink\": 0.5})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import h5py\n",
    "\n",
    "with h5py.File(paths.data / \"dataset_mini.hdf5\", \"r\") as f:\n",
    "    actions = [action.decode(\"utf-8\") for action in set(f[\"actions\"])]\n",
    "\n",
    "pddl = symbolic.Pddl(str(paths.domain_pddl), str(paths.problem_pddl))\n",
    "stats = dnf_utils.compute_pddl_statistics(pddl, actions=actions)\n",
    "\n",
    "plot_predicate_counts(stats)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_dnfs(stats)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run example action skeleton"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def render(world):\n",
    "    \"\"\"Render world.\"\"\"\n",
    "    # pygame.image.save(world.canvas, 'test.png')\n",
    "    img = world.render()\n",
    "    fig = plt.figure(figsize=(7, 7))\n",
    "    plt.imshow(img, interpolation='none')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "\n",
    "from env.gridworld.world import World\n",
    "\n",
    "# Initialize random seed\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "\n",
    "# Create world\n",
    "world = World(pddl, config)\n",
    "print(f\"Initial state: {world.state}\\n\")\n",
    "render(world)\n",
    "\n",
    "# List valid actions\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('goto(door_key)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('pick(door_key, room_a)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('goto(door)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('unlock(door, door_key)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('place(door_key, room_a)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('open(door)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('goto(chest_key)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('pick(chest_key, room_a)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('enter(room_b, door)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('goto(chest)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('unlock(chest, chest_key)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('place(chest_key, room_b)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('open(chest)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.execute('pick(trophy, chest)')\n",
    "render(world)\n",
    "world.list_valid_actions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "world.is_goal_satisfied()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
